{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe5839e-8cde-4146-9845-0917c412cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100  Loss: 1.3856  Accuracy: 0.00%\n",
      "Epoch 11/100  Loss: 0.7792  Accuracy: 100.00%\n",
      "Epoch 21/100  Loss: 0.4343  Accuracy: 100.00%\n",
      "Epoch 31/100  Loss: 0.2450  Accuracy: 100.00%\n",
      "Epoch 41/100  Loss: 0.1479  Accuracy: 100.00%\n",
      "Epoch 51/100  Loss: 0.0975  Accuracy: 100.00%\n",
      "Epoch 61/100  Loss: 0.0694  Accuracy: 100.00%\n",
      "Epoch 71/100  Loss: 0.0525  Accuracy: 100.00%\n",
      "Epoch 81/100  Loss: 0.0415  Accuracy: 100.00%\n",
      "Epoch 91/100  Loss: 0.0340  Accuracy: 100.00%\n",
      "Epoch 100/100  Loss: 0.0291  Accuracy: 100.00%\n",
      "\n",
      "Final prediction after training:\n",
      "Predicted word: down\n",
      "Target word: down\n",
      "Final Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# Helper functions\n",
    "def softmax(x):\n",
    "    exps = [math.exp(i) for i in x]\n",
    "    total = sum(exps)\n",
    "    return [i/total for i in exps]\n",
    "\n",
    "def tanh(x):\n",
    "    return [math.tanh(i) for i in x]\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return [1 - math.tanh(i)**2 for i in x]\n",
    "\n",
    "def vector_add(v1, v2):\n",
    "    return [i + j for i, j in zip(v1, v2)]\n",
    "\n",
    "def matrix_vector_mul(matrix, vector):\n",
    "    return [sum(m*v for m,v in zip(row, vector)) for row in matrix]\n",
    "\n",
    "def outer_product(v1, v2):\n",
    "    return [[a*b for b in v2] for a in v1]\n",
    "\n",
    "def cross_entropy(predicted, target_index):\n",
    "    return -math.log(predicted[target_index] + 1e-10)\n",
    "\n",
    "def one_hot(index, size):\n",
    "    vec = [0]*size\n",
    "    vec[index] = 1\n",
    "    return vec\n",
    "\n",
    "# Initialize Parameters\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "output_size = 4\n",
    "\n",
    "def random_matrix(rows, cols):\n",
    "    return [[random.uniform(-0.1, 0.1) for _ in range(cols)] for _ in range(rows)]\n",
    "\n",
    "def zero_vector(size):\n",
    "    return [0.0 for _ in range(size)]\n",
    "\n",
    "# Weights\n",
    "W_xh = random_matrix(hidden_size, input_size)\n",
    "W_hh = random_matrix(hidden_size, hidden_size)\n",
    "b_h = zero_vector(hidden_size)\n",
    "\n",
    "W_hy = random_matrix(output_size, hidden_size)\n",
    "b_y = zero_vector(output_size)\n",
    "\n",
    "# Training Data\n",
    "word_to_idx = {\"the\":0, \"cat\":1, \"sat\":2, \"down\":3}\n",
    "idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
    "\n",
    "inputs = [\"the\", \"cat\", \"sat\"]\n",
    "target = \"down\"\n",
    "\n",
    "input_vectors = [one_hot(word_to_idx[word], input_size) for word in inputs]\n",
    "target_index = word_to_idx[target]\n",
    "\n",
    "# Training settings\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    h = zero_vector(hidden_size)\n",
    "    h_list = []\n",
    "    y = None\n",
    "\n",
    "    for x in input_vectors:\n",
    "        pre_activation = vector_add(\n",
    "            matrix_vector_mul(W_xh, x),\n",
    "            matrix_vector_mul(W_hh, h)\n",
    "        )\n",
    "        pre_activation = vector_add(pre_activation, b_h)\n",
    "        h = tanh(pre_activation)\n",
    "        h_list.append(h)\n",
    "\n",
    "    logits = vector_add(matrix_vector_mul(W_hy, h), b_y)\n",
    "    y = softmax(logits)\n",
    "\n",
    "    # Loss\n",
    "    loss = cross_entropy(y, target_index)\n",
    "\n",
    "    # Prediction and Accuracy\n",
    "    predicted_index = y.index(max(y))\n",
    "    is_correct = (predicted_index == target_index)\n",
    "    accuracy = 100.0 if is_correct else 0.0\n",
    "\n",
    "    # Backward pass\n",
    "    dW_xh = [[0.0]*input_size for _ in range(hidden_size)]\n",
    "    dW_hh = [[0.0]*hidden_size for _ in range(hidden_size)]\n",
    "    db_h = [0.0 for _ in range(hidden_size)]\n",
    "\n",
    "    dW_hy = [[0.0]*hidden_size for _ in range(output_size)]\n",
    "    db_y = [0.0 for _ in range(output_size)]\n",
    "\n",
    "    dy = y[:]\n",
    "    dy[target_index] -= 1\n",
    "\n",
    "    for i in range(output_size):\n",
    "        for j in range(hidden_size):\n",
    "            dW_hy[i][j] += dy[i] * h[j]\n",
    "    for i in range(output_size):\n",
    "        db_y[i] += dy[i]\n",
    "\n",
    "    dh = [0.0 for _ in range(hidden_size)]\n",
    "    for j in range(hidden_size):\n",
    "        for i in range(output_size):\n",
    "            dh[j] += W_hy[i][j] * dy[i]\n",
    "\n",
    "    for t in reversed(range(len(input_vectors))):\n",
    "        dh_raw = [a*b for a,b in zip(dh, tanh_derivative(h_list[t]))]\n",
    "\n",
    "        for i in range(hidden_size):\n",
    "            for j in range(input_size):\n",
    "                dW_xh[i][j] += dh_raw[i] * input_vectors[t][j]\n",
    "            for j in range(hidden_size):\n",
    "                prev_h = h_list[t-1] if t != 0 else zero_vector(hidden_size)\n",
    "                dW_hh[i][j] += dh_raw[i] * prev_h[j]\n",
    "            db_h[i] += dh_raw[i]\n",
    "\n",
    "        dh_new = [0.0 for _ in range(hidden_size)]\n",
    "        for j in range(hidden_size):\n",
    "            for i in range(hidden_size):\n",
    "                dh_new[j] += W_hh[i][j] * dh_raw[i]\n",
    "        dh = dh_new\n",
    "\n",
    "    # Update weights\n",
    "    for i in range(hidden_size):\n",
    "        for j in range(input_size):\n",
    "            W_xh[i][j] -= learning_rate * dW_xh[i][j]\n",
    "        for j in range(hidden_size):\n",
    "            W_hh[i][j] -= learning_rate * dW_hh[i][j]\n",
    "        b_h[i] -= learning_rate * db_h[i]\n",
    "\n",
    "    for i in range(output_size):\n",
    "        for j in range(hidden_size):\n",
    "            W_hy[i][j] -= learning_rate * dW_hy[i][j]\n",
    "        b_y[i] -= learning_rate * db_y[i]\n",
    "\n",
    "    # Print every 10 epochs\n",
    "    if epoch % 10 == 0 or epoch == epochs-1:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}  Loss: {loss:.4f}  Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Final result\n",
    "print(\"\\nFinal prediction after training:\")\n",
    "print(f\"Predicted word: {idx_to_word[predicted_index]}\")\n",
    "print(f\"Target word: {target}\")\n",
    "print(f\"Final Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e7c49c-9c7d-4d19-b804-9d2e459da92e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
